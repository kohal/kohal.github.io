---
    layout: post
    title: kafka初见
---

- > [kafka官方文档](http://kafka.apachecn.org/documentation.html#introduction)

- ![kafka组件交互](../images/kafka-design.jpg)

- kafka topic出现 **Under Replicated Partitions** 问题
    * topic partition情况
    ![topic partition](../images/kafka_ur.png)

    * 导致consumer.poll(）一直堵塞，堵塞code：kafka-client:1.0.1  
        
        ```java    
            /** 
            * Block until the provided request future request has finished or the timeout has expired.
            * @param future The request future to wait for
            * @param timeout The maximum duration (in ms) to wait for the request
            * @return true if the future is done, false otherwise
            * @throws WakeupException if {@link #wakeup()} is called from another thread
            * @throws InterruptException if the calling thread is interrupted
            */
            //ConsumerNetworkClient:185L
            public boolean poll(RequestFuture<?> future, long timeout) {
                long begin = time.milliseconds();
                long remaining = timeout;
                long now = begin;
                do {
                    poll(remaining, now, future);
                    now = time.milliseconds();
                    long elapsed = now - begin;
                    remaining = timeout - elapsed;
                } while (!future.isDone() && remaining > 0);
                return future.isDone();
            }

        ```  

    *  debug的exception:   
        `org.apache.kafka.common.errors.LeaderNotAvailableException: There is no leader for this topic-partition as we are in the middle of a leadership election.`

- Kafka Replication
    - Partition 有两种副本：Leader，Follower；
    - Leader 负责维护 in-sync-replicas(ISR)
        * replica.lag.time.max.ms：默认为10000，如果 follower 落后于 leader 的消息数超过这个数值时，leader 就将 follower 从 isr 列表中移除；
        * num.replica.fetchers，默认为1，用于从 leader 同步数据的 fetcher 线程数；
        * min.insync.replica：Producer 端使用来用于保证 Durability（持久性）；

-  Under Replicated Partitions 
    - 当发现 replica 的配置与集群的不同时，一般情况都是集群上的 replica 少于配置数时，可以从以下几个角度来排查问题：
        * JMX 监控: kafka.server:type=ReplicaManagername=UnderReplicatedPartitions；
        * 可能的原因：
            1. Broker 挂了？  (最终发现是broker：11 挂了问题)
            2. Controller 的问题？
            3. zooKeeper 的问题？
            4. Network 的问题？
        * 解决办法：
            1. 调整 ISR 的设置；
            2. Broker 扩容。

- >  Kafka 不是用大多数投票选择 leader 。Kafka 动态维护了一个同步状态的备份的集合 （a set of in-sync replicas）， 简称 ISR ，在这个集合中的节点都是和 leader 保持高度一致的，只有这个集合的成员才 有资格被选举为 leader，一条消息必须被这个集合 所有 节点读取并追加到日志中了，这条消息才能视为提交。这个 ISR 集合发生变化会在 ZooKeeper 持久化，正因为如此，这个集合中的任何一个节点都有资格被选为 leader 。

-  当ISR中的broker节点都挂了，就会导致该partion leader一直选举不出，功能不可用。这个就是导致之前kafka poll消息堵塞的问题所在


- Consumer rebablance   
    * tips:Consumer Coordinator一般指的是运行在broker上的group Coordinator，用于管理Consumer Group中各个成员，每个KafkaServer都有一个GroupCoordinator实例，管理多个消费者组，主要用于offset位移管理和Consumer Rebalance